{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa27ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 300)\n",
    "pd.set_option(\"display.max_rows\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbbb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f6292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "churn = pd.read_csv(\"telecom_churn_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bb4b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBILE_NUMBER</td>\n",
       "      <td>Customer phone number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIRCLE_ID</td>\n",
       "      <td>Telecom circle area to which the customer belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Local calls - within same telecom circle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acronyms                                           Descriptions\n",
       "0  MOBILE_NUMBER                              Customer phone number\n",
       "1      CIRCLE_ID  Telecom circle area to which the customer belo...\n",
       "2            LOC           Local calls - within same telecom circle"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at initial rows of the data\n",
    "churn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb38cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38 entries, 0 to 37\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Acronyms      38 non-null     object\n",
      " 1   Descriptions  38 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 736.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# feature type summary\n",
    "churn.info(verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16e910d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>MOBILE_NUMBER</td>\n",
       "      <td>Customer phone number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Acronyms               Descriptions\n",
       "count              38                     38\n",
       "unique             38                     38\n",
       "top     MOBILE_NUMBER  Customer phone number\n",
       "freq                1                      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at data statistics\n",
    "churn.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "262c355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create backup of data\n",
    "original = churn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d867bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#ID cols: 2\n",
      "#Date cols:12\n",
      "#Numeric cols:2\n",
      "#Category cols:8\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# create column name list by types of columns\n",
    "id_cols = ['mobile_number', 'circle_id']\n",
    "\n",
    "date_cols = ['last_date_of_month_6',\n",
    "             'last_date_of_month_7',\n",
    "             'last_date_of_month_8',\n",
    "             'last_date_of_month_9',\n",
    "             'date_of_last_rech_6',\n",
    "             'date_of_last_rech_7',\n",
    "             'date_of_last_rech_8',\n",
    "             'date_of_last_rech_9',\n",
    "             'date_of_last_rech_data_6',\n",
    "             'date_of_last_rech_data_7',\n",
    "             'date_of_last_rech_data_8',\n",
    "             'date_of_last_rech_data_9'\n",
    "            ]\n",
    "\n",
    "cat_cols =  ['night_pck_user_6',\n",
    "             'night_pck_user_7',\n",
    "             'night_pck_user_8',\n",
    "             'night_pck_user_9',\n",
    "             'fb_user_6',\n",
    "             'fb_user_7',\n",
    "             'fb_user_8',\n",
    "             'fb_user_9'\n",
    "            ]\n",
    "\n",
    "num_cols = [column for column in churn.columns if column not in id_cols + date_cols + cat_cols]\n",
    "\n",
    "# print the number of columns in each list\n",
    "print(\"#ID cols: %d\\n#Date cols:%d\\n#Numeric cols:%d\\n#Category cols:%d\" % (len(id_cols), len(date_cols), len(num_cols), len(cat_cols)))\n",
    "\n",
    "# check if we have missed any column or not\n",
    "print(len(id_cols) + len(date_cols) + len(num_cols) + len(cat_cols) == churn.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efe1338a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acronyms        0.0\n",
       "Descriptions    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at missing value ratio in each column\n",
    "churn.isnull().sum()*100/churn.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05a24e1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'count_rech_2g_6', 'count_rech_2g_7',\\n       'count_rech_2g_8', 'count_rech_2g_9', 'count_rech_3g_6',\\n       'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\\n       'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8',\\n       'max_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/1425098989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                  ]\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mchurn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecharge_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'count_rech_2g_6', 'count_rech_2g_7',\\n       'count_rech_2g_8', 'count_rech_2g_9', 'count_rech_3g_6',\\n       'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\\n       'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8',\\n       'max_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# some recharge columns have minimum value of 1 while some don't\n",
    "recharge_cols = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "                 'count_rech_2g_6', 'count_rech_2g_7', 'count_rech_2g_8', 'count_rech_2g_9',\n",
    "                 'count_rech_3g_6', 'count_rech_3g_7', 'count_rech_3g_8', 'count_rech_3g_9',\n",
    "                 'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9',\n",
    "                 'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "                 ]\n",
    "\n",
    "churn[recharge_cols].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12d196f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'total_rech_data_6'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/2002938225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# It is also observed that the recharge date and the recharge value are missing together which means the customer didn't recharge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_rech_data_6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_of_last_rech_data_6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"total_rech_data_6\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"date_of_last_rech_data_6\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'total_rech_data_6'"
     ]
    }
   ],
   "source": [
    "# It is also observed that the recharge date and the recharge value are missing together which means the customer didn't recharge\n",
    "churn.loc[churn.total_rech_data_6.isnull() & churn.date_of_last_rech_data_6.isnull(), [\"total_rech_data_6\", \"date_of_last_rech_data_6\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "713d074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of recharge columns where we will impute missing values with zeroes\n",
    "zero_impute = ['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8', 'total_rech_data_9',\n",
    "        'av_rech_amt_data_6', 'av_rech_amt_data_7', 'av_rech_amt_data_8', 'av_rech_amt_data_9',\n",
    "        'max_rech_data_6', 'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ef44504",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9', 'max_rech_data_6',\\n       'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/2398966055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# impute missing values with 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchurn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzero_impute\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchurn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzero_impute\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9', 'max_rech_data_6',\\n       'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# impute missing values with 0\n",
    "churn[zero_impute] = churn[zero_impute].apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aa43b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value ratio:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9', 'max_rech_data_6',\\n       'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/3099282297.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# now, let's make sure values are imputed correctly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Missing value ratio:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mzero_impute\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['total_rech_data_6', 'total_rech_data_7', 'total_rech_data_8',\\n       'total_rech_data_9', 'av_rech_amt_data_6', 'av_rech_amt_data_7',\\n       'av_rech_amt_data_8', 'av_rech_amt_data_9', 'max_rech_data_6',\\n       'max_rech_data_7', 'max_rech_data_8', 'max_rech_data_9'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# now, let's make sure values are imputed correctly\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(churn[zero_impute].isnull().sum()*100/churn.shape[1])\n",
    "\n",
    "# summary\n",
    "print(\"\\n\\nSummary statistics\\n\")\n",
    "print(churn[zero_impute].describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222c1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping:  (38, 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'id_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_17624/5754131.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# drop id and date columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape before dropping: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mchurn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_cols\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdate_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shape after dropping: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'id_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# drop id and date columns\n",
    "print(\"Shape before dropping: \", churn.shape)\n",
    "churn = churn.drop(id_cols + date_cols, axis=1)\n",
    "print(\"Shape after dropping: \", churn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96418b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value ratio:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8',\\n       'night_pck_user_9', 'fb_user_6', 'fb_user_7', 'fb_user_8', 'fb_user_9'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/3465628966.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# missing value ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Missing value ratio:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3464\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3466\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['night_pck_user_6', 'night_pck_user_7', 'night_pck_user_8',\\n       'night_pck_user_9', 'fb_user_6', 'fb_user_7', 'fb_user_8', 'fb_user_9'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# missing value ratio\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(churn[cat_cols].isnull().sum()*100/churn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "767635a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acronyms</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Descriptions</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  include\n",
       "0  Acronyms         True\n",
       "1  Descriptions     True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace missing values with '-1' in categorical columns\n",
    "churn[cat_cols] = churn[cat_cols].apply(lambda x: x.fillna(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9f831c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 columns dropped.\n"
     ]
    }
   ],
   "source": [
    "# missing value ratio\n",
    "print(\"Missing value ratio:\\n\")\n",
    "print(churn[cat_cols].isnull().sum()*100/churn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbfce7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Columns : 2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NASHEE~1\\AppData\\Local\\Temp/ipykernel_9560/1928403530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Total Columns :'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# using MICE technique to impute missing values in the rest of the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMICE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mchurn_imputed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMICE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_imputations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchurn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "initial_cols = churn.shape[1]\n",
    "\n",
    "MISSING_THRESHOLD = 0.7\n",
    "\n",
    "include_cols = list(churn.apply(lambda column: True if column.isnull().sum()/churn.shape[0] < MISSING_THRESHOLD else False))\n",
    "\n",
    "drop_missing = pd.DataFrame({'features':churn.columns , 'include': include_cols})\n",
    "drop_missing.loc[drop_missing.include == True,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf46465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "churn = churn.loc[:, include_cols]\n",
    "\n",
    "dropped_cols = churn.shape[1] - initial_cols\n",
    "print(\"{0} columns dropped.\".format(dropped_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245131bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_cols = churn.columns\n",
    "print('Total Columns :',len(churn_cols))\n",
    "# using MICE technique to impute missing values in the rest of the columns\n",
    "from fancyimpute import MICE\n",
    "churn_imputed = MICE(n_imputations=1).complete(churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b154f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert imputed numpy array to pandas dataframe\n",
    "churn = pd.DataFrame(churn_imputed, columns=churn_cols)\n",
    "print(churn.isnull().sum()*100/churn.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total data recharge amount for June and July --> number of recharges * average recharge amount\n",
    "churn['total_data_rech_6'] = churn.total_rech_data_6 * churn.av_rech_amt_data_6\n",
    "churn['total_data_rech_7'] = churn.total_rech_data_7 * churn.av_rech_amt_data_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total recharge amount for June and July --> call recharge amount + data recharge amount\n",
    "churn['amt_data_6'] = churn.total_rech_amt_6 + churn.total_data_rech_6\n",
    "churn['amt_data_7'] = churn.total_rech_amt_7 + churn.total_data_rech_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average recharge done by customer in June and July\n",
    "churn['av_amt_data_6_7'] = (churn.amt_data_6 + churn.amt_data_7)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d57d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the 70th percentile recharge amount\n",
    "print(\"Recharge amount at 70th percentile: {0}\".format(churn.av_amt_data_6_7.quantile(0.7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ce464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only those customers who have recharged their mobiles with more than or equal to 70th percentile amount\n",
    "churn_filtered = churn.loc[churn.av_amt_data_6_7 >= churn.av_amt_data_6_7.quantile(0.7), :]\n",
    "churn_filtered = churn_filtered.reset_index(drop=True)\n",
    "churn_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1fe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete variables created to filter high-value customers\n",
    "churn_filtered = churn_filtered.drop(['total_data_rech_6', 'total_data_rech_7',\n",
    "                                      'amt_data_6', 'amt_data_7', 'av_amt_data_6_7'], axis=1)\n",
    "churn_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd5d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total incoming and outgoing minutes of usage\n",
    "churn_filtered['total_calls_mou_9'] = churn_filtered.total_ic_mou_9 + churn_filtered.total_og_mou_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df196fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 2g and 3g data consumption\n",
    "churn_filtered['total_internet_mb_9'] =  churn_filtered.vol_2g_mb_9 + churn_filtered.vol_3g_mb_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c34433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create churn variable: those who have not used either calls or internet in the month of September are customers who have churned\n",
    "\n",
    "# 0 - not churn, 1 - churn\n",
    "churn_filtered['churn'] = churn_filtered.apply(lambda row: 1 if (row.total_calls_mou_9 == 0 and row.total_internet_mb_9 == 0) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507710b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete derived variables\n",
    "churn_filtered = churn_filtered.drop(['total_calls_mou_9', 'total_internet_mb_9'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to category\n",
    "churn_filtered.churn = churn_filtered.churn.astype(\"category\")\n",
    "\n",
    "# print churn ratio\n",
    "print(\"Churn Ratio:\")\n",
    "print(churn_filtered.churn.value_counts()*100/churn_filtered.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ef7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_filtered['arpu_diff'] = churn_filtered.arpu_8 - ((churn_filtered.arpu_6 + churn_filtered.arpu_7)/2)\n",
    "\n",
    "churn_filtered['onnet_mou_diff'] = churn_filtered.onnet_mou_8 - ((churn_filtered.onnet_mou_6 + churn_filtered.onnet_mou_7)/2)\n",
    "\n",
    "churn_filtered['offnet_mou_diff'] = churn_filtered.offnet_mou_8 - ((churn_filtered.offnet_mou_6 + churn_filtered.offnet_mou_7)/2)\n",
    "\n",
    "churn_filtered['roam_ic_mou_diff'] = churn_filtered.roam_ic_mou_8 - ((churn_filtered.roam_ic_mou_6 + churn_filtered.roam_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['roam_og_mou_diff'] = churn_filtered.roam_og_mou_8 - ((churn_filtered.roam_og_mou_6 + churn_filtered.roam_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['loc_og_mou_diff'] = churn_filtered.loc_og_mou_8 - ((churn_filtered.loc_og_mou_6 + churn_filtered.loc_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['std_og_mou_diff'] = churn_filtered.std_og_mou_8 - ((churn_filtered.std_og_mou_6 + churn_filtered.std_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['isd_og_mou_diff'] = churn_filtered.isd_og_mou_8 - ((churn_filtered.isd_og_mou_6 + churn_filtered.isd_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['spl_og_mou_diff'] = churn_filtered.spl_og_mou_8 - ((churn_filtered.spl_og_mou_6 + churn_filtered.spl_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['total_og_mou_diff'] = churn_filtered.total_og_mou_8 - ((churn_filtered.total_og_mou_6 + churn_filtered.total_og_mou_7)/2)\n",
    "\n",
    "churn_filtered['loc_ic_mou_diff'] = churn_filtered.loc_ic_mou_8 - ((churn_filtered.loc_ic_mou_6 + churn_filtered.loc_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['std_ic_mou_diff'] = churn_filtered.std_ic_mou_8 - ((churn_filtered.std_ic_mou_6 + churn_filtered.std_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['isd_ic_mou_diff'] = churn_filtered.isd_ic_mou_8 - ((churn_filtered.isd_ic_mou_6 + churn_filtered.isd_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['spl_ic_mou_diff'] = churn_filtered.spl_ic_mou_8 - ((churn_filtered.spl_ic_mou_6 + churn_filtered.spl_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['total_ic_mou_diff'] = churn_filtered.total_ic_mou_8 - ((churn_filtered.total_ic_mou_6 + churn_filtered.total_ic_mou_7)/2)\n",
    "\n",
    "churn_filtered['total_rech_num_diff'] = churn_filtered.total_rech_num_8 - ((churn_filtered.total_rech_num_6 + churn_filtered.total_rech_num_7)/2)\n",
    "\n",
    "churn_filtered['total_rech_amt_diff'] = churn_filtered.total_rech_amt_8 - ((churn_filtered.total_rech_amt_6 + churn_filtered.total_rech_amt_7)/2)\n",
    "\n",
    "churn_filtered['max_rech_amt_diff'] = churn_filtered.max_rech_amt_8 - ((churn_filtered.max_rech_amt_6 + churn_filtered.max_rech_amt_7)/2)\n",
    "\n",
    "churn_filtered['total_rech_data_diff'] = churn_filtered.total_rech_data_8 - ((churn_filtered.total_rech_data_6 + churn_filtered.total_rech_data_7)/2)\n",
    "\n",
    "churn_filtered['max_rech_data_diff'] = churn_filtered.max_rech_data_8 - ((churn_filtered.max_rech_data_6 + churn_filtered.max_rech_data_7)/2)\n",
    "\n",
    "churn_filtered['av_rech_amt_data_diff'] = churn_filtered.av_rech_amt_data_8 - ((churn_filtered.av_rech_amt_data_6 + churn_filtered.av_rech_amt_data_7)/2)\n",
    "\n",
    "churn_filtered['vol_2g_mb_diff'] = churn_filtered.vol_2g_mb_8 - ((churn_filtered.vol_2g_mb_6 + churn_filtered.vol_2g_mb_7)/2)\n",
    "\n",
    "churn_filtered['vol_3g_mb_diff'] = churn_filtered.vol_3g_mb_8 - ((churn_filtered.vol_3g_mb_6 + churn_filtered.vol_3g_mb_7)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at summary of one of the difference variables\n",
    "churn_filtered['total_og_mou_diff'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all variables relating to 9th month\n",
    "churn_filtered = churn_filtered.filter(regex='[^9]$', axis=1)\n",
    "churn_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all names that end with 9\n",
    "col_9_names = churn.filter(regex='9$', axis=1).columns\n",
    "\n",
    "# update num_cols and cat_cols column name list\n",
    "cat_cols = [col for col in cat_cols if col not in col_9_names]\n",
    "cat_cols.append('churn')\n",
    "num_cols = [col for col in churn_filtered.columns if col not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns types\n",
    "churn_filtered[num_cols] = churn_filtered[num_cols].apply(pd.to_numeric)\n",
    "churn_filtered[cat_cols] = churn_filtered[cat_cols].apply(lambda column: column.astype(\"category\"), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa9c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plotting functions\n",
    "def data_type(variable):\n",
    "    if variable.dtype == np.int64 or variable.dtype == np.float64:\n",
    "        return 'numerical'\n",
    "    elif variable.dtype == 'category':\n",
    "        return 'categorical'\n",
    "    \n",
    "def univariate(variable, stats=True):\n",
    "    \n",
    "    if data_type(variable) == 'numerical':\n",
    "        sns.distplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.describe())\n",
    "    \n",
    "    elif data_type(variable) == 'categorical':\n",
    "        sns.countplot(variable)\n",
    "        if stats == True:\n",
    "            print(variable.value_counts())\n",
    "            \n",
    "    else:\n",
    "        print(\"Invalid variable passed: either pass a numeric variable or a categorical vairable.\")\n",
    "        \n",
    "def bivariate(var1, var2):\n",
    "    if data_type(var1) == 'numerical' and data_type(var2) == 'numerical':\n",
    "        sns.regplot(var1, var2)\n",
    "    elif (data_type(var1) == 'categorical' and data_type(var2) == 'numerical') or (data_type(var1) == 'numerical' and data_type(var2) == 'categorical'):        \n",
    "        sns.boxplot(var1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.arpu_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.loc_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99b6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.std_og_t2o_mou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.onnet_mou_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c43be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate(churn.offnet_mou_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(churn_filtered.churn, churn_filtered.aon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bdda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(churn_filtered.sep_vbc_3g, churn_filtered.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate(churn_filtered.spl_og_mou_8, churn_filtered.churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(churn_filtered.churn, churn_filtered.night_pck_user_8, normalize='columns')*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed983f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(churn_filtered.churn, churn_filtered.sachet_3g_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92100bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(array, k=3):\n",
    "    upper_limit = array.mean() + k*array.std()\n",
    "    lower_limit = array.mean() - k*array.std()\n",
    "    array[array<lower_limit] = lower_limit\n",
    "    array[array>upper_limit] = upper_limit\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c67e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of capping\n",
    "sample_array = list(range(100))\n",
    "\n",
    "# add outliers to the data\n",
    "sample_array[0] = -9999\n",
    "sample_array[99] = 9999\n",
    "\n",
    "# cap outliers\n",
    "sample_array = np.array(sample_array)\n",
    "print(\"Array after capping outliers: \\n\", cap_outliers(sample_array, k=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap outliers in the numeric columns\n",
    "churn_filtered[num_cols] = churn_filtered[num_cols].apply(cap_outliers, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb7c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import sensitivity_specificity_support\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76299e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change churn to numeric\n",
    "churn_filtered['churn'] = pd.to_numeric(churn_filtered['churn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf489e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test\n",
    "X = churn_filtered.drop(\"churn\", axis = 1)\n",
    "y = churn_filtered.churn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shapes of train and test sets\n",
    "X_train.shape\n",
    "y_train.shape\n",
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# aggregate the categorical variables\n",
    "train.groupby('night_pck_user_6').churn.mean()\n",
    "train.groupby('night_pck_user_7').churn.mean()\n",
    "train.groupby('night_pck_user_8').churn.mean()\n",
    "train.groupby('fb_user_6').churn.mean()\n",
    "train.groupby('fb_user_7').churn.mean()\n",
    "train.groupby('fb_user_8').churn.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec019f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace categories with aggregated values in each categorical column\n",
    "mapping = {'night_pck_user_6' : {-1: 0.099165, 0: 0.066797, 1: 0.087838},\n",
    "           'night_pck_user_7' : {-1: 0.115746, 0: 0.055494, 1: 0.051282},\n",
    "           'night_pck_user_8' : {-1: 0.141108, 0: 0.029023, 1: 0.016194},\n",
    "           'fb_user_6'        : {-1: 0.099165, 0: 0.069460, 1: 0.067124},\n",
    "           'fb_user_7'        : {-1: 0.115746, 0: 0.059305, 1: 0.055082},\n",
    "           'fb_user_8'        : {-1: 0.141108, 0: 0.066887, 1: 0.024463}\n",
    "          }\n",
    "X_train.replace(mapping, inplace = True)\n",
    "X_test.replace(mapping, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type of categorical columns - make sure they are numeric\n",
    "X_train[[col for col in cat_cols if col not in ['churn']]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7878419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply pca to train data\n",
    "pca = Pipeline([('scaler', StandardScaler()), ('pca', PCA())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_train)\n",
    "churn_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd78a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract pca model from pipeline\n",
    "pca = pca.named_steps['pca']\n",
    "\n",
    "# look at explainded variance of PCA components\n",
    "print(pd.Series(np.round(pca.explained_variance_ratio_.cumsum(), 4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5314d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature variance\n",
    "features = range(pca.n_components_)\n",
    "cumulative_variance = np.round(np.cumsum(pca.explained_variance_ratio_)*100, decimals=4)\n",
    "plt.figure(figsize=(175/20,100/20)) # 100 elements on y-axis; 175 elements on x-axis; 20 is normalising factor\n",
    "plt.plot(cumulative_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "PCA_VARS = 60\n",
    "steps = [('scaler', StandardScaler()),\n",
    "         (\"pca\", PCA(n_components=PCA_VARS)),\n",
    "         (\"logistic\", LogisticRegression(class_weight='balanced'))\n",
    "        ]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# check score on train data\n",
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance\n",
    "y_train.value_counts()/y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "pca = PCA()\n",
    "\n",
    "# logistic regression - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "logistic = LogisticRegression(class_weight={0:0.1, 1: 0.9})\n",
    "\n",
    "# create pipeline\n",
    "steps = [(\"scaler\", StandardScaler()), \n",
    "         (\"pca\", pca),\n",
    "         (\"logistic\", logistic)\n",
    "        ]\n",
    "\n",
    "# compile pipeline\n",
    "pca_logistic = Pipeline(steps)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {'pca__n_components': [60, 80], 'logistic__C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=pca_logistic, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51509fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1c2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation results\n",
    "pd.DataFrame(model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e47c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b23973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ea5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "forest = RandomForestClassifier(class_weight={0:0.1, 1: 0.9}, n_jobs = -1)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {\"criterion\": ['gini', 'entropy'], \"max_features\": ['auto', 0.4]}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=forest, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf278bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ecc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb3319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416ca74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a random forest model on train data\n",
    "max_features = int(round(np.sqrt(X_train.shape[1])))    # number of variables to consider to split each node\n",
    "print(max_features)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_features=max_features, class_weight={0:0.1, 1: 0.9}, oob_score=True, random_state=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4adf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076efdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOB score\n",
    "rf_model.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667dbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictors\n",
    "features = churn_filtered.drop('churn', axis=1).columns\n",
    "\n",
    "# feature_importance\n",
    "importance = rf_model.feature_importances_\n",
    "\n",
    "# create dataframe\n",
    "feature_importance = pd.DataFrame({'variables': features, 'importance_percentage': importance*100})\n",
    "feature_importance = feature_importance[['variables', 'importance_percentage']]\n",
    "\n",
    "# sort features\n",
    "feature_importance = feature_importance.sort_values('importance_percentage', ascending=False).reset_index(drop=True)\n",
    "print(\"Sum of importance=\", feature_importance.importance_percentage.sum())\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dba48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top 'n' features\n",
    "top_n = 30\n",
    "top_features = feature_importance.variables[0:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17750f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature correlation\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] =(10,10)\n",
    "mycmap = sns.diverging_palette(199, 359, s=99, center=\"light\", as_cmap=True)\n",
    "sns.heatmap(data=X_train[top_features].corr(), center=0.0, cmap=mycmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a3394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = ['total_ic_mou_8', 'total_rech_amt_diff', 'total_og_mou_8', 'arpu_8', 'roam_ic_mou_8', 'roam_og_mou_8', \n",
    "                'std_ic_mou_8', 'av_rech_amt_data_8', 'std_og_mou_8']\n",
    "X_train = X_train[top_features]\n",
    "X_test = X_test[top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "steps = [('scaler', StandardScaler()), \n",
    "         (\"logistic\", LogisticRegression(class_weight={0:0.1, 1:0.9}))\n",
    "        ]\n",
    "\n",
    "# compile pipeline\n",
    "logistic = Pipeline(steps)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {'logistic__C': [0.1, 0.5, 1, 2, 3, 4, 5, 10], 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=logistic, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185a27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", model.best_score_)\n",
    "print(\"Best hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9138cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(model, 'models/rf_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92451519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Load the model from the file \n",
    "rf_pickle_model = joblib.load('models/rf_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774afe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded model to make predictions\n",
    "response_rf_model = rf_pickle_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred_load = rf_pickle_model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm_load = confusion_matrix(y_test, y_pred_load)\n",
    "print(cm_load)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity_load, specificity_load, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity_load, 2), \"\\n\", \"Specificity: \\t\", round(specificity_load, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob_load = rf_pickle_model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC:    \\t\", round(roc_auc_score(y_test, y_pred_prob_load),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe28212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict churn on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# create onfusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "sensitivity, specificity, _ = sensitivity_specificity_support(y_test, y_pred, average='binary')\n",
    "print(\"Sensitivity: \\t\", round(sensitivity, 2), \"\\n\", \"Specificity: \\t\", round(specificity, 2), sep='')\n",
    "\n",
    "# check area under curve\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "print(\"ROC:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a5bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = model.best_estimator_.named_steps['logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d8413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intercept\n",
    "intercept_df = pd.DataFrame(logistic_model.intercept_.reshape((1,1)), columns = ['intercept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficients\n",
    "coefficients = logistic_model.coef_.reshape((9, 1)).tolist()\n",
    "coefficients = [val for sublist in coefficients for val in sublist]\n",
    "coefficients = [round(coefficient, 3) for coefficient in coefficients]\n",
    "\n",
    "logistic_features = list(X_train.columns)\n",
    "coefficients_df = pd.DataFrame(logistic_model.coef_, columns=logistic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate dataframes\n",
    "coefficients = pd.concat([intercept_df, coefficients_df], axis=1)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c222fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Business Insights\n",
    "Telecom company needs to pay attention to the roaming rates. They need to provide good offers to the customers who are using services from a roaming zone.\n",
    "The company needs to focus on the STD and ISD rates. Perhaps, the rates are too high. Provide them with some kind of STD and ISD packages.\n",
    "To look into both of the issues stated above, it is desired that the telecom company collects customer query and complaint data and work on their services according to the needs of customers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
